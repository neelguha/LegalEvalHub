{
  "task_id": "contract_nli_no_licensing",
  "name": "contract_nli_no_licensing",
  "family": "LegalBench",
  "short_description": "Evaluates if an NDA clause denies rights to Confidential Information.",
  "long_description": "The 'contract_nli_no_licensing' task specifically measures the ability to interpret clauses within Non-Disclosure Agreements (NDAs) regarding the rights conferred to the Receiving Party concerning Confidential Information. It focuses on determining whether a given clause explicitly states that the Agreement does not grant the Receiving Party any rights to such information. This task requires a nuanced understanding of contract language and the implications of confidentiality provisions, which are critical in legal practice to protect sensitive information during business transactions.\n\nLegal reasoning in this task involves binary classification, where participants must analyze the text of the clause and assess its alignment with the hypothesis regarding the rights to Confidential Information. This evaluation is crucial for legal AI systems, as it tests their capability to accurately interpret legal documents, which is fundamental for ensuring compliance and safeguarding proprietary information in various legal contexts. Understanding the implications of confidentiality clauses is essential for legal practitioners, as these provisions play a pivotal role in maintaining the integrity of sensitive business information and preventing unauthorized disclosures.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 170,
  "tags": [
    "LegalBench",
    "confidentiality",
    "contract law",
    "interpretation"
  ],
  "document_type": "contract clause",
  "min_input_length": 19,
  "max_input_length": 435,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[ContractNLI](https://stanfordnlp.github.io/contract-nli/)",
  "license": "[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)",
  "legal_reasoning_type": "Interpretation",
  "task_type": "Binary classification"
}