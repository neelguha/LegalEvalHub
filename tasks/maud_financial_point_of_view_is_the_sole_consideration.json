{
  "task_id": "maud_financial_point_of_view_is_the_sole_consideration",
  "name": "maud_financial_point_of_view_is_the_sole_consideration",
  "family": "LegalBench",
  "short_description": "Evaluates if 'financial point of view' is the sole consideration in merger offers.",
  "long_description": "This task measures the legal capability to interpret merger agreements, specifically focusing on the consideration of financial perspectives in determining the superiority of offers. It requires the ability to analyze contractual language and assess whether financial considerations are the exclusive factor in evaluating offers, which is a critical aspect of merger negotiations. The task involves binary classification, where the model must choose between two options based on the provided excerpt from a merger agreement.\n\nThe importance of this task lies in its relevance to legal AI systems that assist in contract analysis and negotiation strategies. Understanding whether financial considerations are paramount can significantly impact the decision-making process in mergers and acquisitions. This task is grounded in the legal concepts of contract law and the principles governing merger agreements, where the interpretation of terms can lead to different strategic outcomes for the parties involved. As such, it serves as a benchmark for evaluating the interpretative capabilities of AI in the context of complex legal documents.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 113,
  "tags": [
    "LegalBench",
    "corporate law",
    "interpretation",
    "merger agreement"
  ],
  "document_type": "merger agreement",
  "min_input_length": 90,
  "max_input_length": 1353,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[Atticus Project](https://www.atticusprojectai.org/maud)",
  "license": "[CC By 4.0](https://creativecommons.org/licenses/by/4.0/)",
  "legal_reasoning_type": "Interpretation",
  "task_type": "Binary classification"
}