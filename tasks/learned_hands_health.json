{
  "task_id": "learned_hands_health",
  "name": "learned_hands_health",
  "family": "LegalBench",
  "short_description": "Classifies user posts for legal issues related to health services.",
  "long_description": "The 'learned_hands_health' task evaluates the ability of legal AI systems to identify and classify user-generated content that implicates legal issues surrounding health services. This includes determining whether posts discuss access to health services, payment for medical care, public health benefits, and rights protection within medical contexts. By focusing on these specific legal capabilities, the task measures the AI's proficiency in recognizing relevant legal concerns that may arise in everyday health-related scenarios.\n\nThis task requires issue-spotting legal reasoning, where the AI must discern subtle cues within user posts that indicate potential legal issues. The binary classification nature of the task means that the AI must accurately categorize posts as either implicating legal issues (Yes) or not (No). This capability is crucial for evaluating legal AI systems, as it reflects their ability to assist users in navigating complex health law matters, which can significantly impact individuals' access to necessary services and their rights in medical environments. Understanding these legal concepts is vital for ensuring that AI tools can effectively support users in making informed decisions regarding their health care rights and obligations.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 232,
  "tags": [
    "LegalBench",
    "access to care",
    "health law",
    "issue spotting"
  ],
  "document_type": "legal question",
  "min_input_length": 47,
  "max_input_length": 2113,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[Learned Hands](https://spot.suffolklitlab.org/data/#learnedhands)",
  "license": "[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)",
  "legal_reasoning_type": "Issue-spotting",
  "task_type": "Binary classification"
}