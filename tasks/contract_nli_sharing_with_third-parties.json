{
  "task_id": "contract_nli_sharing_with_third-parties",
  "name": "contract_nli_sharing_with_third-parties",
  "family": "LegalBench",
  "short_description": "Evaluates if NDAs allow sharing confidential information with third parties.",
  "long_description": "The 'contract_nli_sharing_with_third-parties' task measures the legal capability to interpret non-disclosure agreements (NDAs) specifically regarding the sharing of confidential information with third parties. This task requires an understanding of the nuances in contract language and the implications of confidentiality clauses, focusing on whether such clauses permit the Receiving Party to disclose information to consultants, agents, or professional advisors. Legal reasoning in this context involves careful analysis of contractual language to determine the presence or absence of specific permissions related to information sharing.\n\nThis task is crucial for evaluating legal AI systems as it tests their ability to accurately interpret and classify legal clauses based on their implications. Understanding the legal effects of contract provisions is fundamental in legal practice, as misinterpretations can lead to significant legal consequences. The background of this task is rooted in contract law, particularly in the context of confidentiality and the obligations of parties under NDAs. By assessing AI's performance in this area, we can gauge its readiness for real-world legal applications, ensuring that it can assist legal professionals in drafting, reviewing, and negotiating contracts effectively.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 188,
  "tags": [
    "LegalBench",
    "confidentiality",
    "contract law",
    "interpretation"
  ],
  "document_type": "contract clause",
  "min_input_length": 16,
  "max_input_length": 435,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[ContractNLI](https://stanfordnlp.github.io/contract-nli/)",
  "license": "[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)",
  "legal_reasoning_type": "Interpretation",
  "task_type": "Binary classification"
}