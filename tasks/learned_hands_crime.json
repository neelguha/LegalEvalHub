{
  "task_id": "learned_hands_crime",
  "name": "learned_hands_crime",
  "family": "LegalBench",
  "short_description": "Classifies user posts for legal issues related to crime.",
  "long_description": "The 'learned_hands_crime' task evaluates the capability of a legal AI system to identify and classify user-generated content that implicates issues within the criminal justice system. This includes recognizing discussions about criminal charges, trials, imprisonment, or victimization. The task requires the AI to engage in issue-spotting, a critical legal reasoning skill that involves discerning relevant legal issues from a broader context of information. By determining whether a post discusses criminal law matters, the AI demonstrates its understanding of legal concepts and the nuances of criminal liability and victim rights.\n\nThis task is essential for assessing the effectiveness of legal AI systems in real-world applications, particularly in environments where individuals seek legal guidance online. By accurately classifying posts related to crime, the AI can help direct users to appropriate legal resources or professionals, thereby enhancing access to justice. The 'learned_hands_crime' task is grounded in foundational legal principles surrounding criminal law, including the definitions of crimes, the rights of defendants, and the protections afforded to victims, making it a vital benchmark for evaluating AI's performance in legal contexts.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 694,
  "tags": [
    "LegalBench",
    "criminal law",
    "issue spotting",
    "issue-spotting",
    "legal knowledge"
  ],
  "document_type": "legal question",
  "min_input_length": 30,
  "max_input_length": 2111,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[Learned Hands](https://spot.suffolklitlab.org/data/#learnedhands)",
  "license": "[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)",
  "legal_reasoning_type": "Issue-spotting",
  "task_type": "Binary classification"
}