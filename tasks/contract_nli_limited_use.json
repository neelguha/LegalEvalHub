{
  "task_id": "contract_nli_limited_use",
  "name": "contract_nli_limited_use",
  "family": "LegalBench",
  "short_description": "Evaluates if NDA clauses restrict use of Confidential Information to specified purposes.",
  "long_description": "The 'contract_nli_limited_use' task measures the legal capability to interpret non-disclosure agreement (NDA) clauses, specifically assessing whether a clause restricts the Receiving Party's use of Confidential Information to the purposes explicitly stated in the agreement. This task requires a nuanced understanding of contract law and the ability to analyze the implications of contractual language, focusing on the interpretation of terms and their legal effect. Participants must discern between clauses that affirmatively restrict use and those that do not, which is critical for ensuring compliance with confidentiality obligations in legal agreements.\n\nThis task is vital for evaluating legal AI systems as it tests their ability to perform binary classification on legal texts, a fundamental skill in legal analysis. By determining whether a clause entails or contradicts the specified hypothesis, the task highlights the importance of precise language in legal documents and the potential consequences of misinterpretation. Understanding these concepts is essential for legal professionals, as it directly impacts the enforceability of NDAs and the protection of sensitive information in business contexts.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 216,
  "tags": [
    "LegalBench",
    "confidentiality",
    "contract law",
    "interpretation"
  ],
  "document_type": "contract clause",
  "min_input_length": 19,
  "max_input_length": 358,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[ContractNLI](https://stanfordnlp.github.io/contract-nli/)",
  "license": "[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)",
  "legal_reasoning_type": "Interpretation",
  "task_type": "Binary classification"
}