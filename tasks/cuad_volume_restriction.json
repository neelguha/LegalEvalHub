{
  "task_id": "cuad_volume_restriction",
  "name": "cuad_volume_restriction",
  "family": "LegalBench",
  "short_description": "Classifies clauses specifying fee increases or consent for exceeding usage thresholds.",
  "long_description": "The 'cuad_volume_restriction' task evaluates the ability to identify contractual clauses that impose conditions on the use of products or services based on volume thresholds. Specifically, it measures whether a clause includes stipulations for fee increases or consent requirements when one party's usage exceeds a predetermined limit. This task is crucial for understanding how contractual obligations can vary based on usage levels, which is a common aspect of many service agreements and contracts in various industries.\n\nLegal reasoning for this task involves interpretation skills, as it requires the model to discern the nuances of language used in contractual clauses. The ability to accurately classify these clauses is essential for legal AI systems, as it reflects their competence in navigating complex contractual language and understanding the implications of volume restrictions on parties' rights and obligations. Given the prevalence of such clauses in contracts, this task is significant for ensuring that AI systems can assist legal professionals in contract review and compliance effectively.\n\nVolume restrictions are a key concept in contract law, often tied to pricing structures and service delivery. Understanding these clauses helps in assessing potential liabilities and costs that may arise from exceeding agreed-upon usage levels, making this task an important benchmark for evaluating the performance of legal AI tools in real-world applications.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 328,
  "tags": [
    "LegalBench",
    "contract law",
    "fee structure",
    "interpretation"
  ],
  "document_type": "contract clause",
  "min_input_length": 15,
  "max_input_length": 597,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[Atticus Project](https://www.atticusprojectai.org/cuad>)",
  "license": "[CC By 4.0](https://creativecommons.org/licenses/by/4.0/)",
  "legal_reasoning_type": "Interpretation",
  "task_type": "Binary classification"
}