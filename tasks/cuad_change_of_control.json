{
  "task_id": "cuad_change_of_control",
  "name": "cuad_change_of_control",
  "family": "LegalBench",
  "short_description": "Evaluates if a clause allows termination or requires consent upon change of control.",
  "long_description": "The 'cuad_change_of_control' task measures the legal capability to interpret contractual clauses related to changes in control, such as mergers or asset transfers. Specifically, it assesses whether a clause grants one party the right to terminate the contract or necessitates consent or notice from the counterparty in the event of a change of control. This task requires nuanced legal reasoning, as it involves understanding the implications of contractual language and the legal consequences of such changes on the parties involved.\n\nThis task is crucial for evaluating legal AI systems, as it directly relates to the interpretation of contract law, which is foundational in corporate transactions. Understanding change of control clauses is essential for parties involved in mergers and acquisitions, as these clauses can significantly impact the rights and obligations of the parties. By accurately classifying these clauses, AI systems can assist legal professionals in contract review, ensuring that critical terms are identified and understood, thereby facilitating informed decision-making in corporate governance and compliance matters.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 422,
  "tags": [
    "LegalBench",
    "change of control",
    "corporate law",
    "interpretation"
  ],
  "document_type": "contract clause",
  "min_input_length": 18,
  "max_input_length": 661,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[Atticus Project](https://www.atticusprojectai.org/cuad>)",
  "license": "[CC By 4.0](https://creativecommons.org/licenses/by/4.0/)",
  "legal_reasoning_type": "Interpretation",
  "task_type": "Binary classification"
}