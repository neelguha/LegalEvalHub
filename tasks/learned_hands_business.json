{
  "task_id": "learned_hands_business",
  "name": "learned_hands_business",
  "family": "LegalBench",
  "short_description": "Classifies user posts for legal issues related to business operations.",
  "long_description": "The 'learned_hands_business' task evaluates the ability to identify and classify legal issues that arise in the context of small businesses and nonprofits. This includes a range of topics such as incorporation, licensing, taxation, and regulatory compliance, as well as challenges related to disasters and bankruptcies. By focusing on these specific areas, the task measures the model's understanding of the legal landscape that business owners navigate, which is crucial for providing accurate legal guidance and support.\n\nThe task requires issue-spotting legal reasoning, where the model must discern whether a user’s inquiry implicates relevant legal concerns. This type of analysis is essential for legal AI systems, as it helps ensure that users receive appropriate advice and resources tailored to their business-related legal questions. Understanding these legal concepts is vital for developing AI tools that can assist individuals and organizations in making informed decisions, thereby enhancing access to legal information and support in the business sector.\n\nGiven the complexities of business law and the variety of issues that can arise, this task serves as an important benchmark for evaluating the effectiveness of legal AI systems. It highlights the necessity for AI to not only recognize legal terminology but also to contextualize it within the specific challenges faced by businesses, ensuring that the technology can adequately support users in real-world scenarios.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 180,
  "tags": [
    "LegalBench",
    "business law",
    "issue spotting",
    "regulatory compliance"
  ],
  "document_type": "legal question",
  "min_input_length": 43,
  "max_input_length": 1408,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher Ré",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[Learned Hands](https://spot.suffolklitlab.org/data/#learnedhands)",
  "license": "[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)",
  "legal_reasoning_type": "Issue-spotting",
  "task_type": "Binary classification"
}