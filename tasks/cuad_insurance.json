{
  "task_id": "cuad_insurance",
  "name": "cuad_insurance",
  "family": "LegalBench",
  "short_description": "Classifies clauses requiring insurance for one party's benefit in contracts.",
  "long_description": "The 'cuad_insurance' task evaluates the ability to identify contractual clauses that impose a requirement for insurance to be maintained by one party for the benefit of the counterparty. This task specifically measures the legal capability of interpreting contract language and understanding the implications of insurance requirements within contractual agreements. It requires the model to discern whether a clause explicitly states that one party must hold insurance that protects the other party, which is a critical aspect of risk management in contractual relationships.\n\nLegal reasoning in this task involves interpretation of contract clauses, where the model must analyze the language used and determine the presence of specific insurance obligations. This type of analysis is essential for legal AI systems, as it reflects the practical application of contract law principles and the importance of insurance in mitigating potential liabilities. Understanding these requirements is vital for parties entering contracts, as it ensures that they are adequately protected against unforeseen events that could lead to financial loss.\n\nThe task is significant for evaluating legal AI systems because it tests their ability to handle nuanced legal language and make determinations that could impact the enforcement of contractual obligations. The background legal concepts involve contract law, specifically the obligations and rights that arise from contractual agreements, and the role of insurance as a protective measure in business transactions. By assessing AI's performance in this area, we can better understand its readiness for real-world legal applications.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 1036,
  "tags": [
    "LegalBench",
    "contract law",
    "insurance requirement",
    "interpretation",
    "rule application"
  ],
  "document_type": "contract clause",
  "min_input_length": 12,
  "max_input_length": 736,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[Atticus Project](https://www.atticusprojectai.org/cuad>)",
  "license": "[CC By 4.0](https://creativecommons.org/licenses/by/4.0/)",
  "legal_reasoning_type": "Interpretation",
  "task_type": "Binary classification"
}