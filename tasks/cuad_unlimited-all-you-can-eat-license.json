{
  "task_id": "cuad_unlimited-all-you-can-eat-license",
  "name": "cuad_unlimited-all-you-can-eat-license",
  "family": "LegalBench",
  "short_description": "Classifies clauses granting unlimited usage licenses in contracts.",
  "long_description": "The 'cuad_unlimited-all-you-can-eat-license' task evaluates the ability of legal AI systems to identify and classify contractual clauses that grant an 'enterprise,' 'all you can eat,' or unlimited usage license. This task specifically measures the AI's capability to interpret legal language and discern the implications of such licenses within contracts. Understanding these clauses is crucial as they define the extent of usage rights granted to one party, which can significantly impact the contractual relationship and obligations between the parties involved.\n\nTo successfully complete this task, the AI must engage in legal reasoning that involves interpretation of contract language, recognizing the nuances of licensing terms, and distinguishing between clauses that provide unlimited rights versus those that do not. This task is essential for evaluating legal AI systems, as it reflects their proficiency in handling real-world legal documents and their ability to assist legal professionals in contract review processes. The background legal concepts involved include contract law principles, particularly those related to licensing agreements and the rights and responsibilities they entail.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 54,
  "tags": [
    "LegalBench",
    "contract law",
    "interpretation",
    "licensing"
  ],
  "document_type": "contract clause",
  "min_input_length": 13,
  "max_input_length": 250,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[Atticus Project](https://www.atticusprojectai.org/cuad>)",
  "license": "[CC By 4.0](https://creativecommons.org/licenses/by/4.0/)",
  "legal_reasoning_type": "Interpretation",
  "task_type": "Binary classification"
}