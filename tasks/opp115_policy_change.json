{
  "task_id": "opp115_policy_change",
  "name": "opp115_policy_change",
  "family": "LegalBench",
  "short_description": "Classifies clauses on user notification regarding privacy policy changes.",
  "long_description": "The 'opp115_policy_change' task evaluates the capability of legal AI systems to interpret clauses from privacy policies specifically concerning user notifications about changes to those policies. This task measures the AI's understanding of privacy law principles, particularly how transparency and user consent are addressed in legal texts. By classifying whether a clause indicates if and how users will be informed about changes, the task assesses the AI's ability to navigate the complexities of privacy regulations and user rights.\n\nLegal reasoning in this task involves interpretation, as the AI must discern the intent and clarity of the language used in the privacy policy clauses. This requires not only a grasp of legal terminology but also an understanding of the broader context of privacy laws, such as the General Data Protection Regulation (GDPR) and other relevant frameworks that mandate clear communication with users regarding their data rights. Evaluating this task is crucial for assessing the effectiveness of legal AI systems in providing accurate and reliable interpretations of legal documents, which can ultimately influence compliance and user trust in digital platforms.\n\nThe task is grounded in the principles of privacy law, which emphasize the importance of informing users about how their personal information is handled. As privacy policies are often dense and filled with legal jargon, the ability to accurately classify clauses regarding policy changes is vital for ensuring that users are adequately informed, thereby promoting transparency and accountability in data practices.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 439,
  "tags": [
    "LegalBench",
    "interpretation",
    "privacy law",
    "user notification"
  ],
  "document_type": "privacy policy",
  "min_input_length": 10,
  "max_input_length": 428,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[OPP-115](https://usableprivacy.org/data)",
  "license": "Creative Commons Attribution-NonCommercial License",
  "legal_reasoning_type": "Interpretation",
  "task_type": "Binary classification"
}