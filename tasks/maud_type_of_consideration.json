{
  "task_id": "maud_type_of_consideration",
  "name": "maud_type_of_consideration",
  "family": "LegalBench",
  "short_description": "Classify the type of consideration in a merger agreement excerpt.",
  "long_description": "The 'maud_type_of_consideration' task evaluates the ability to interpret and classify the type of consideration specified in merger agreements. This task measures a legal AI system's capability to understand complex contractual language and identify whether the consideration is all cash, all stock, or a mixed form involving both cash and stock. Such classification is crucial for understanding the financial structure of mergers and acquisitions, which can significantly impact stakeholders' interests and the overall success of the transaction.\n\nTo successfully complete this task, legal reasoning and analysis are required, particularly in the realm of interpretation. The AI must discern nuances in the language of the agreement and apply knowledge of legal concepts related to consideration in contracts. This task is important for evaluating legal AI systems because it tests their ability to navigate and interpret specific contractual provisions, which is a fundamental skill for legal practitioners. Understanding the type of consideration in a merger agreement is essential for assessing the implications of the deal, including valuation and negotiation strategies, making this task a vital component of legal education and practice in corporate law.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 173,
  "tags": [
    "LegalBench",
    "consideration",
    "corporate law",
    "interpretation"
  ],
  "document_type": "merger agreement",
  "min_input_length": 46,
  "max_input_length": 1109,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[Atticus Project](https://www.atticusprojectai.org/maud)",
  "license": "[CC By 4.0](https://creativecommons.org/licenses/by/4.0/)",
  "legal_reasoning_type": "Interpretation",
  "task_type": "4-way classification"
}