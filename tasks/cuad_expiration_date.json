{
  "task_id": "cuad_expiration_date",
  "name": "cuad_expiration_date",
  "family": "LegalBench",
  "short_description": "Classify if a contractual clause specifies an expiration date.",
  "long_description": "The 'cuad_expiration_date' task evaluates the ability to identify whether a contractual clause explicitly states the date on which the initial term of the contract expires. This task measures the legal capability of interpreting contract language, focusing on the critical aspect of expiration dates, which are essential for understanding the duration and enforceability of contractual obligations. Accurate identification of expiration dates is vital for parties involved in contracts, as it affects their rights and responsibilities under the agreement.\n\nThis binary classification task requires legal reasoning skills, particularly in the interpretation of contract clauses. Participants must discern the specific language that indicates an expiration date, distinguishing it from other contractual provisions that do not serve this purpose. The importance of this task lies in its ability to assess the effectiveness of legal AI systems in parsing and understanding complex legal documents, ensuring that they can assist legal professionals in contract review and compliance checks. The task is grounded in fundamental legal concepts related to contract law, where expiration dates play a pivotal role in determining the lifecycle of agreements and the timing of obligations.\n",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 882,
  "tags": [
    "LegalBench",
    "contract law",
    "expiration date",
    "interpretation"
  ],
  "document_type": "contract clause",
  "min_input_length": 12,
  "max_input_length": 644,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[Atticus Project](https://www.atticusprojectai.org/cuad>)",
  "license": "[CC By 4.0](https://creativecommons.org/licenses/by/4.0/)",
  "legal_reasoning_type": "Interpretation",
  "task_type": "Binary classification"
}