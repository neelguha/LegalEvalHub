{
  "task_id": "definition_classification",
  "name": "definition_classification",
  "family": "LegalBench",
  "short_description": "Classify sentences from Supreme Court opinions as definitions or not.",
  "long_description": "The 'definition_classification' task evaluates the ability to identify whether a given sentence from a Supreme Court opinion provides a definition of a legal term. This task measures the legal capability of recognizing definitional language, which is crucial for understanding legal texts and the precise meanings of terms as interpreted by the courts. Legal practitioners must be adept at discerning definitions to apply laws accurately and argue effectively in legal contexts.\n\nThis task requires rhetorical analysis and comprehension of legal reasoning, as it involves distinguishing between sentences that merely describe a term and those that explicitly define it. The ability to classify definitions correctly is vital for legal AI systems, as it enhances their understanding of legal language and improves their performance in tasks such as legal research, document review, and automated legal reasoning. The background knowledge of legal concepts and terminology is essential, as definitions often shape the interpretation of laws and impact legal outcomes.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 1345,
  "tags": [
    "LegalBench",
    "legal definition",
    "legal knowledge",
    "rhetorical analysis",
    "rhetorical understanding"
  ],
  "document_type": "judicial opinion",
  "min_input_length": 6,
  "max_input_length": 468,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "Kevin Tobia",
  "license": "[CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/)",
  "legal_reasoning_type": "Rhetorical-analysis",
  "task_type": "Binary classification"
}