{
  "task_id": "unfair_tos",
  "name": "unfair_tos",
  "family": "LegalBench",
  "short_description": "Classify clauses in terms-of-service contracts to identify potentially unfair provisions.",
  "long_description": "The 'unfair_tos' task evaluates the ability to classify clauses from terms-of-service agreements into specific categories, particularly focusing on identifying potentially unfair terms. This task measures the legal capability of interpreting contractual language and understanding the implications of various clauses that may affect consumer rights and obligations. The categories include 'Arbitration', 'Unilateral change', 'Content removal', 'Jurisdiction', 'Choice of law', 'Limitation of liability', 'Unilateral termination', 'Contract by using', and 'Other', with the first eight being of particular concern for fairness in contractual agreements.\n\nLegal reasoning in this task requires a nuanced understanding of contract law and the ability to analyze how specific clauses can impact the balance of power between service providers and users. Evaluating these clauses is crucial for assessing the fairness and transparency of terms-of-service agreements, which are often lengthy and complex, making it challenging for consumers to understand their rights. This task is important for evaluating legal AI systems as it tests their ability to interpret legal texts and apply legal principles in a practical context, ultimately contributing to the development of tools that can assist consumers in navigating digital contracts more effectively.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 3822,
  "tags": [
    "LegalBench",
    "contract law",
    "interpretation",
    "unilateral change"
  ],
  "document_type": "contract clause",
  "min_input_length": 7,
  "max_input_length": 371,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[Claudette](https://arxiv.org/abs/1805.01217)",
  "license": "[CC by 4.0](https://creativecommons.org/licenses/by/4.0/)",
  "legal_reasoning_type": "Interpretation",
  "task_type": "8-way classification"
}