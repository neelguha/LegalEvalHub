{
  "task_id": "opp115_user_choice_control",
  "name": "opp115_user_choice_control",
  "family": "LegalBench",
  "short_description": "Evaluates user choice and control options in privacy policy clauses.",
  "long_description": "The 'opp115_user_choice_control' task measures the capability of legal AI systems to interpret clauses from privacy policies specifically regarding the choices and control options available to users. This task requires a nuanced understanding of privacy law and the obligations of organizations to inform users about their rights and options concerning personal data. The AI must classify whether a given clause effectively communicates these choices, which is critical for ensuring compliance with legal standards and enhancing user trust in data handling practices.\n\nLegal reasoning in this task involves interpretation, as the AI must discern the intent and clarity of language used in privacy policy clauses. This analysis is vital for evaluating legal AI systems because it assesses their ability to navigate complex regulatory environments and provide accurate assessments of legal texts. As privacy regulations evolve, understanding user choice and control is increasingly important, making this task a key benchmark for AI systems that aim to support legal professionals and organizations in maintaining compliance with privacy laws.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 1554,
  "tags": [
    "LegalBench",
    "interpretation",
    "privacy law",
    "user consent"
  ],
  "document_type": "privacy policy",
  "min_input_length": 10,
  "max_input_length": 406,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[OPP-115](https://usableprivacy.org/data)",
  "license": "Creative Commons Attribution-NonCommercial License",
  "legal_reasoning_type": "Interpretation",
  "task_type": "Binary classification"
}