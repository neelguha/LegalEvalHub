{
  "task_id": "telemarketing_sales_rule",
  "name": "telemarketing_sales_rule",
  "family": "LegalBench",
  "short_description": "Evaluates application of telemarketing sales regulations to fact patterns.",
  "long_description": "The 'telemarketing_sales_rule' benchmark task measures the ability to apply specific provisions of the Telemarketing Sales Rule (16 C.F.R. § 310.3(a)(1) and 16 C.F.R. § 310.3(a)(2)) to various fact patterns. This task focuses on identifying whether certain telemarketing practices constitute violations of the regulations that protect consumers from deceptive and abusive practices. Participants are required to analyze fact patterns and determine if the outlined requirements for disclosure and misrepresentation have been met, thus assessing their understanding of consumer protection laws in telemarketing contexts.\n\nThis task requires legal reasoning that involves the application of regulatory standards to hypothetical scenarios. Participants must interpret the legal language of the regulations and apply it to specific situations, making conclusions about compliance or violations. This task is crucial for evaluating legal AI systems, as it tests their capability to navigate complex regulatory frameworks and their ability to understand the nuances of consumer protection laws. Given the prevalence of telemarketing and the potential for consumer fraud, proficiency in applying these regulations is essential for ensuring compliance and protecting consumer rights.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 51,
  "tags": [
    "LegalBench",
    "consumer protection",
    "deceptive practices",
    "rule application",
    "rule conclusion"
  ],
  "document_type": "legal question",
  "min_input_length": 57,
  "max_input_length": 142,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher Ré",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "Jonathan H. Choi",
  "license": "[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)",
  "legal_reasoning_type": "Application/conclusion",
  "task_type": "Binary classification"
}