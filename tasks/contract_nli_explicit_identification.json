{
  "task_id": "contract_nli_explicit_identification",
  "name": "contract_nli_explicit_identification",
  "family": "LegalBench",
  "short_description": "Evaluates identification of Confidential Information in NDA clauses.",
  "long_description": "The 'contract_nli_explicit_identification' task measures the capability to determine whether a specific clause in a Non-Disclosure Agreement (NDA) explicitly states that all Confidential Information must be identified by the Disclosing Party. This task focuses on the interpretation of legal language and the implications of contractual obligations, which are crucial in ensuring that parties understand their rights and responsibilities regarding confidential information. By assessing the clarity and explicitness of such clauses, this task highlights the importance of precise legal drafting in contract law.\n\nLegal reasoning required for this task involves careful analysis and interpretation of contractual language to ascertain whether the clause meets the specified legal criterion. It necessitates a nuanced understanding of contract law principles, particularly those related to confidentiality and the obligations of parties in a contract. This task is vital for evaluating legal AI systems as it tests their ability to comprehend and analyze legal texts accurately, ensuring that they can assist legal professionals in drafting, reviewing, and interpreting contracts effectively. The ability to identify explicit requirements in legal documents is fundamental for risk management and compliance in legal practice.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 117,
  "tags": [
    "LegalBench",
    "confidentiality",
    "contract law",
    "interpretation"
  ],
  "document_type": "contract clause",
  "min_input_length": 19,
  "max_input_length": 418,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[ContractNLI](https://stanfordnlp.github.io/contract-nli/)",
  "license": "[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)",
  "legal_reasoning_type": "Interpretation",
  "task_type": "Binary classification"
}