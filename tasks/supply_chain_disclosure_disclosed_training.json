{
  "task_id": "supply_chain_disclosure_disclosed_training",
  "name": "supply_chain_disclosure_disclosed_training",
  "family": "LegalBench",
  "short_description": "Evaluates disclosure of training on human trafficking in supply chain management.",
  "long_description": "The 'supply_chain_disclosure_disclosed_training' task measures the legal capability to interpret and evaluate supply chain disclosures specifically regarding the training provided to employees and management on human trafficking and slavery. This task requires the application of legal reasoning to determine whether the disclosures adequately inform stakeholders about the extent of training aimed at mitigating risks associated with human trafficking within the supply chains of products. It assesses the clarity and completeness of such disclosures in relation to legal compliance and ethical standards in corporate governance.\n\nThis task is critical for evaluating legal AI systems as it focuses on the intersection of corporate law, ethical business practices, and human rights. Understanding how well companies disclose their training efforts on such significant issues is essential for promoting transparency and accountability in supply chains. The legal concepts involved include corporate responsibility, compliance with anti-trafficking laws, and the ethical obligations of businesses to prevent human rights abuses. By effectively analyzing these disclosures, AI systems can support better regulatory compliance and foster corporate accountability in supply chain practices.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 387,
  "tags": [
    "LegalBench",
    "corporate law",
    "human trafficking",
    "interpretation",
    "rule application"
  ],
  "document_type": "disclosure statement",
  "min_input_length": 107,
  "max_input_length": 5764,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "Adam Chilton & Galit Sarfaty",
  "license": "[CC by 4.0](https://creativecommons.org/licenses/by/4.0/)",
  "legal_reasoning_type": "Interpretation",
  "task_type": "Binary classification"
}