{
  "task_id": "contract_nli_permissible_acquirement_of_similar_information",
  "name": "contract_nli_Permissible acquirement of similar information",
  "family": "LegalBench",
  "short_description": "Evaluates if an NDA clause allows acquiring similar information from third parties.",
  "long_description": "The task 'contract_nli_permissible_acquirement_of_similar_information' measures the legal capability to interpret clauses within Non-Disclosure Agreements (NDAs), specifically focusing on whether such clauses permit the Receiving Party to acquire information that is similar to the Confidential Information from third parties. This evaluation is crucial for understanding the implications of confidentiality obligations and the boundaries of permissible information sharing in contractual relationships. Legal professionals must be adept at discerning these nuances to ensure compliance and protect sensitive information effectively.\n\nThis task requires legal reasoning and analysis, particularly in the realm of interpretation. Participants must assess the language of the contract clauses to determine if they explicitly or implicitly allow for the acquisition of similar information from external sources. This is significant not only for the parties involved in the NDA but also for evaluating the capabilities of legal AI systems in accurately interpreting complex legal texts. A thorough understanding of the legal concepts surrounding confidentiality and information sharing is essential, as these principles underpin many business transactions and legal agreements.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 186,
  "tags": [
    "LegalBench",
    "confidentiality",
    "contract law",
    "interpretation"
  ],
  "document_type": "contract clause",
  "min_input_length": 19,
  "max_input_length": 409,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[ContractNLI](https://stanfordnlp.github.io/contract-nli/)",
  "license": "[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)",
  "legal_reasoning_type": "Interpretation",
  "task_type": "Binary classification"
}