{
  "task_id": "learned_hands_consumer",
  "name": "learned_hands_consumer",
  "family": "LegalBench",
  "short_description": "Classifies user posts for legal issues related to consumer matters.",
  "long_description": "The 'learned_hands_consumer' task evaluates the capability of legal AI systems to identify and classify user-generated content that implicates legal issues concerning consumer matters. This includes a range of topics such as money, insurance, consumer goods, contracts, taxes, and small claims regarding service quality. By analyzing whether a post discusses these issues, the task measures the AI's ability to recognize relevant legal contexts and concerns that consumers may face in everyday situations.\n\nThis task requires issue-spotting legal reasoning, where the AI must discern whether the content of a user post relates to specific legal challenges faced by consumers. The importance of this task lies in its potential to enhance the effectiveness of legal AI systems in providing accurate and relevant legal guidance to users. By accurately classifying posts, these systems can better assist individuals in navigating consumer-related legal issues, thereby improving access to justice and legal resources. The task is grounded in fundamental legal concepts that govern consumer rights and protections, making it a critical component in the development of responsive and responsible legal AI applications.",
  "dataset_url": "https://hazyresearch.stanford.edu/legalbench/",
  "num_samples": 620,
  "tags": [
    "LegalBench",
    "consumer law",
    "contract law",
    "issue spotting",
    "issue-spotting"
  ],
  "document_type": "legal question",
  "min_input_length": 39,
  "max_input_length": 3090,
  "metrics": [
    {
      "name": "accuracy",
      "direction": "maximize"
    },
    {
      "name": "balanced_accuracy",
      "direction": "maximize"
    },
    {
      "name": "f1_macro",
      "direction": "maximize"
    },
    {
      "name": "f1_micro",
      "direction": "maximize"
    },
    {
      "name": "valid_predictions_ratio",
      "direction": "maximize"
    }
  ],
  "contributed_by_name": "Neel Guha",
  "contributed_by_email": "nguha@cs.stanford.edu",
  "paper_url": "https://arxiv.org/abs/2308.11462",
  "paper_title": "LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models",
  "paper_authors": [
    "Neel Guha",
    "Julian Nyarko",
    "Daniel E. Ho",
    "Christopher RÃ©",
    "Adam Chilton",
    "Aditya Narayana",
    "Alex Chohlas-Wood",
    "Austin Peters",
    "Brandon Waldon",
    "Daniel N. Rockmore",
    "Diego Zambrano",
    "Dmitry Talisman",
    "Enam Hoque",
    "Faiz Surani",
    "Frank Fagan",
    "Galit Sarfaty",
    "Gregory M. Dickinson",
    "Haggai Porat",
    "Jason Hegland",
    "Jessica Wu",
    "Joe Nudell",
    "Joel Niklaus",
    "John Nay",
    "Jonathan H. Choi",
    "Kevin Tobia",
    "Margaret Hagan",
    "Megan Ma",
    "Michael Livermore",
    "Nikon Rasumov-Rahe",
    "Nils Holzenberger",
    "Noam Kolt",
    "Peter Henderson",
    "Sean Rehaag",
    "Sharad Goel",
    "Shang Gao",
    "Spencer Williams",
    "Sunny Gandhi",
    "Tom Zur",
    "Varun Iyer",
    "Zehua Li"
  ],
  "source": "[Learned Hands](https://spot.suffolklitlab.org/data/#learnedhands)",
  "license": "[CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)",
  "legal_reasoning_type": "Issue-spotting",
  "task_type": "Binary classification"
}